{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we are given a data set of different hand written numbers from 0 to 9 . \n",
    "###our task is to train a neural network to classify the hand writtem image files and build a model which predicts \n",
    "## from the data set and evaluate the performance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import the data which is built in with the keras dataset\n",
    "mnist = tf.keras.datasets.mnist### 28*28 images of hand written digits 0-9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### perform the train and test split \n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "### the data is within a 28*28 grid , \n",
    "##so we normalize the data which helps the network to calculate the inputs better\n",
    "x_train = tf.keras.utils.normalize(x_train , axis = 1) \n",
    "x_test = tf.keras.utils.normalize(x_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[10]### example that the 10th instance of our data set is a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building up the model : \n",
    "model = tf.keras.models.Sequential()#### we want to have a feed forward network\n",
    "model.add(tf.keras.layers.Flatten())### flattening the data helps to compress the input in such a which allows the network perform better\n",
    "### we would want to have 2 hidden layers with 128 neurons and each have rectified linear function as the activation function \n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "### as the labels are 0 to 9 so 10 output nodes are needed and the activation function is softmax function \n",
    "model.add(tf.keras.layers.Dense(10,activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam' ,loss='sparse_categorical_crossentropy' ,metrics = ['accuracy'] )\n",
    "#### we use the to go optimizer adam because its recommended as the most used optimizer function in different tensorflow literatures\n",
    "###sgd or stochastic gradient descent will also work well. \n",
    "#### loss function is sparse categorical because the number of labels are 10 and if the label number was only \n",
    "### 4 or 5 we caould have used categorical cross entropy \n",
    "### we would like to evaluate our performace as so the metrics is set to accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### with only ten epochs the network learns the data set with an accuracy of 99.6percent!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = model.predict([x_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss , val_acc = model.evaluate(x_test , y_test)\n",
    "print (val_loss ,val_acc)\n",
    "#### evaluation :  accuracy 97.5% (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(predictions[50]))#### originally the 50th data of our data set are array of pixels which resembles '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[50])\n",
    "plt.show()#### our model perfectly identifies that the 50th data instance is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###the end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
